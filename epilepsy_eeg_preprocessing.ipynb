{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "yKG3wUSanUJd"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries"
      ],
      "metadata": {
        "id": "yKG3wUSanUJd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tpRPhkMmpN_",
        "outputId": "b69e3432-05a0-403a-d35a-ecd8760e16b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-1.7.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.3)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from mne) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from mne) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (24.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.8.1)\n",
            "Requirement already satisfied: scipy>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from mne) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.66.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (4.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (2.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5.0->mne) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2024.2.2)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-1.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install mne\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import kurtosis, skew\n",
        "from scipy.signal import argrelextrema, welch\n",
        "from scipy.integrate import cumtrapz\n",
        "import statistics\n",
        "import time\n",
        "\n",
        "import mne # to read the .edf files\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "1lxghp1yncz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# some pre-processing used function from pyeeg\n",
        "\n",
        "def bin_power(X, Band, Fs):\n",
        "    \"\"\"Compute power in each frequency bin specified by Band from FFT result of\n",
        "\n",
        "    Parameters\n",
        "    -----------\n",
        "\n",
        "    X: list: a 1-D real time series.\n",
        "    Band; list\n",
        "        boundary frequencies (in Hz) of bins. They can be unequal bins, e.g.\n",
        "        [0.5,4,7,12,30] which are delta, theta, alpha and beta respectively.\n",
        "        You can also use range() function of Python to generate equal bins and\n",
        "        pass the generated list to this function.\n",
        "\n",
        "        Each element of Band is a physical frequency and shall not exceed the\n",
        "        Nyquist frequency, i.e., half of sampling frequency.\n",
        "\n",
        "\n",
        "\n",
        "    Fs: integer: the sampling rate in physical frequency\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "\n",
        "    Power: list: spectral power in each frequency bin.\n",
        "\n",
        "    Power_ratio: list:\n",
        "        spectral power in each frequency bin normalized by total power in ALL\n",
        "        frequency bins.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    C = np.fft.fft(X)\n",
        "    C = abs(C)\n",
        "    Power = np.zeros(len(Band) - 1)\n",
        "    for Freq_Index in range(0, len(Band) - 1):\n",
        "        Freq = float(Band[Freq_Index])\n",
        "        Next_Freq = float(Band[Freq_Index + 1])\n",
        "        Power[Freq_Index] = sum(\n",
        "            C[int(np.floor(Freq / Fs * len(X))):\n",
        "                int(np.floor(Next_Freq / Fs * len(X)))]\n",
        "        )\n",
        "    Power_Ratio = Power / sum(Power)\n",
        "    return Power, Power_Ratio\n",
        "\n",
        "\n",
        "def hfd(X, Kmax):\n",
        "    \"\"\" Compute Higuchi Fractal Dimension of a time series X. kmax\n",
        "     is an HFD parameter\n",
        "    \"\"\"\n",
        "    L = []\n",
        "    x = []\n",
        "    N = len(X)\n",
        "    for k in range(1, Kmax):\n",
        "        Lk = []\n",
        "        for m in range(0, k):\n",
        "            Lmk = 0\n",
        "            for i in range(1, int(np.floor((N - m) / k))):\n",
        "                Lmk += abs(X[m + i * k] - X[m + i * k - k])\n",
        "            Lmk = Lmk * (N - 1) / np.floor((N - m) / float(k)) / k\n",
        "            Lk.append(Lmk)\n",
        "        L.append(np.log(np.mean(Lk)))\n",
        "        x.append([np.log(float(1) / k), 1])\n",
        "\n",
        "    (p, _, _, _) = np.linalg.lstsq(x, L)\n",
        "    return p[0]\n",
        "\n",
        "\n",
        "\n",
        "def pfd(X, D=None):\n",
        "    \"\"\"Compute Petrosian Fractal Dimension of a time series from either two\n",
        "    cases below:\n",
        "        1. X, the time series of type list (default)\n",
        "        2. D, the first order differential sequence of X (if D is provided,\n",
        "           recommended to speed up)\n",
        "\n",
        "    In case 1, D is computed using Numpy's difference function.\n",
        "\n",
        "    To speed up, it is recommended to compute D before calling this function\n",
        "    because D may also be used by other functions whereas computing it here\n",
        "    again will slow down.\n",
        "    \"\"\"\n",
        "    if D is None:\n",
        "        D = np.diff(X)\n",
        "        D = D.tolist()\n",
        "    N_delta = 0  # number of sign changes in derivative of the signal\n",
        "    for i in range(1, len(D)):\n",
        "        if D[i] * D[i - 1] < 0:\n",
        "            N_delta += 1\n",
        "    n = len(X)\n",
        "    return np.log10(n) / (\n",
        "        np.log10(n) + np.log10(n / n + 0.4 * N_delta)\n",
        "    )\n",
        "\n",
        "\n",
        "def hurst(X):\n",
        "    \"\"\" Compute the Hurst exponent of X. If the output H=0.5,the behavior\n",
        "    of the time-series is similar to random walk. If H<0.5, the time-series\n",
        "    cover less \"distance\" than a random walk, vice verse.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    X: list: a time series\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    H: float:  Hurst exponent\n",
        "    \"\"\"\n",
        "    X = np.array(X)\n",
        "    N = X.size\n",
        "    T = np.arange(1, N + 1)\n",
        "    Y = np.cumsum(X)\n",
        "    Ave_T = Y / T\n",
        "\n",
        "    S_T = np.zeros(N)\n",
        "    R_T = np.zeros(N)\n",
        "\n",
        "    for i in range(N):\n",
        "        S_T[i] = np.std(X[:i + 1])\n",
        "        X_T = Y - T * Ave_T[i]\n",
        "        R_T[i] = np.ptp(X_T[:i + 1])\n",
        "\n",
        "    R_S = R_T / S_T\n",
        "    R_S = np.log(R_S)[1:]\n",
        "    n = np.log(T)[1:]\n",
        "    A = np.column_stack((n, np.ones(n.size)))\n",
        "    [m, c] = np.linalg.lstsq(A, R_S)[0]\n",
        "    H = m\n",
        "    return H\n",
        "\n",
        "\n",
        "def spectral_entropy(X, Band, Fs, Power_Ratio=None):\n",
        "    \"\"\"Compute spectral entropy of a time series from either two cases below:\n",
        "    1. X, the time series (default)\n",
        "    2. Power_Ratio, a list of normalized signal power in a set of frequency\n",
        "    bins defined in Band (if Power_Ratio is provided, recommended to speed up)\n",
        "\n",
        "    In case 1, Power_Ratio is computed by bin_power() function.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    To speed up, it is recommended to compute Power_Ratio before calling this\n",
        "    function because it may also be used by other functions whereas computing\n",
        "    it here again will slow down.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    X: list: a 1-D real time series.\n",
        "\n",
        "    Band: list\n",
        "\n",
        "        boundary frequencies (in Hz) of bins. They can be unequal bins, e.g.\n",
        "        [0.5,4,7,12,30] which are delta, theta, alpha and beta respectively.\n",
        "        You can also use range() function of Python to generate equal bins and\n",
        "        pass the generated list to this function.\n",
        "\n",
        "        Each element of Band is a physical frequency and shall not exceed the\n",
        "        Nyquist frequency, i.e., half of sampling frequency.\n",
        "\n",
        "\n",
        "    Fs: integer: the sampling rate in physical frequency\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "\n",
        "    As indicated in return line\n",
        "\n",
        "    See Also\n",
        "    --------\n",
        "    bin_power: pyeeg function that computes spectral power in frequency bins\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    if Power_Ratio is None:\n",
        "        Power, Power_Ratio = bin_power(X, Band, Fs)\n",
        "\n",
        "    Spectral_Entropy = 0\n",
        "    for i in range(0, len(Power_Ratio) - 1):\n",
        "        Spectral_Entropy += Power_Ratio[i] * np.log(Power_Ratio[i])\n",
        "    Spectral_Entropy /= np.log(\n",
        "        len(Power_Ratio)\n",
        "    )  # to save time, minus one is omitted\n",
        "    return -1 * Spectral_Entropy\n",
        "\n",
        "\n",
        "def hjorth(X, D=None):\n",
        "    \"\"\" Compute Hjorth mobility and complexity of a time series from either two\n",
        "    cases below:\n",
        "        1. X, the time series of type list (default)\n",
        "        2. D, a first order differential sequence of X (if D is provided,\n",
        "           recommended to speed up)\n",
        "\n",
        "    In case 1, D is computed using Numpy's Difference function.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    To speed up, it is recommended to compute D before calling this function\n",
        "    because D may also be used by other functions whereas computing it here\n",
        "    again will slow down.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    X: list: a time series\n",
        "\n",
        "    D: list: first order differential sequence of a time series\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "\n",
        "    As indicated in return line\n",
        "\n",
        "    Hjorth mobility and complexity\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    if D is None:\n",
        "        D = np.diff(X)\n",
        "        D = D.tolist()\n",
        "\n",
        "    D.insert(0, X[0])  # pad the first difference\n",
        "    D = np.array(D)\n",
        "\n",
        "    n = len(X)\n",
        "\n",
        "    M2 = float(sum(D ** 2)) / n\n",
        "    TP = sum(np.array(X) ** 2)\n",
        "    M4 = 0\n",
        "    for i in range(1, len(D)):\n",
        "        M4 += (D[i] - D[i - 1]) ** 2\n",
        "    M4 = M4 / n\n",
        "\n",
        "    return np.sqrt(M2 / TP), np.sqrt(\n",
        "        float(M4) * TP / M2 / M2\n",
        "    )  # Hjorth Mobility and Complexity"
      ],
      "metadata": {
        "id": "tv03cLbKngA4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read the edf and print stuff first\n",
        "# def eeg_visualize(file, start_time, end_time):\n",
        "def eeg_visualize(file):\n",
        "    raw = mne.io.read_raw_edf(file)\n",
        "    n = 2\n",
        "\n",
        "    # MNE-Python's interactive data browser to get a better visualization\n",
        "    raw.plot()\n",
        "\n",
        "    # select a time frame\n",
        "    start, stop = raw.time_as_index([100, 115])  # 100 s to 115 s data segment\n",
        "    temp, times = raw[:, start:stop]\n",
        "    fig, axs = plt.subplots(n)\n",
        "    fig.suptitle('Patient EEG')\n",
        "    plt.xlabel('time (s)')\n",
        "    plt.ylabel('MEG data (T)')\n",
        "    for i in range(n):\n",
        "        axs[i].plot(times, temp[i].T)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "0wApsRlNoACy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature extracting process\n",
        "def eeg_features(data):\n",
        "    data = np.asarray(data)\n",
        "    res  = np.zeros([22])\n",
        "    Kmax = 5\n",
        "    # M    = 10\n",
        "    # R    = 0.3\n",
        "    Band = [1,5,10,15,20,25]\n",
        "    Fs   = 256\n",
        "    power, power_ratio = bin_power(data, Band, Fs)\n",
        "    f, P = welch(data, fs=Fs, window='hann', noverlap=0, nfft=int(256.))       # Signal power spectrum\n",
        "    area_freq = cumtrapz(P, f, initial=0)\n",
        "    res[0] = np.sqrt(np.sum(np.power(data, 2)) / data.shape[0])                   # amplitude RMS\n",
        "    res[1] = statistics.stdev(data)**2                                            # variance\n",
        "    res[2] = kurtosis(data)                                                       # kurtosis\n",
        "    res[3] = skew(data)                                                           # skewness\n",
        "    res[4] = max(data)                                                            # max amplitude\n",
        "    res[5] = min(data)                                                            # min amplitude\n",
        "    res[6] = len(argrelextrema(data, np.greater)[0])                              # number of local extrema or peaks\n",
        "    res[7] = ((data[:-1] * data[1:]) < 0).sum()                                   # number of zero crossings\n",
        "    res[8] = hfd(data, Kmax)                                                      # Higuchi Fractal Dimension\n",
        "    res[9] = pfd(data)                                                            # Petrosian Fractal Dimension\n",
        "    res[10] = hurst(data)                                                         # Hurst exponent\n",
        "    res[11] = spectral_entropy(data, Band, Fs, Power_Ratio=power_ratio)           # spectral entropy (1.21s)\n",
        "    res[12] = area_freq[-1]                                                       # total power\n",
        "    res[13] = f[np.where(area_freq >= res[12] / 2)[0][0]]                         # median frequency\n",
        "    res[14] = f[np.argmax(P)]                                                     # peak frequency\n",
        "    res[15], res[16] = hjorth(data)                                               # Hjorth mobility and complexity\n",
        "    res[17] = power_ratio[0]\n",
        "    res[18] = power_ratio[1]\n",
        "    res[19] = power_ratio[2]\n",
        "    res[20] = power_ratio[3]\n",
        "    res[21] = power_ratio[4]\n",
        "    # res[22] = pyeeg.samp_entropy(data, M, R)             # sample entropy\n",
        "    # res[23] = pyeeg.ap_entropy(data, M, R)             # approximate entropy (1.14s)\n",
        "    return (res)"
      ],
      "metadata": {
        "id": "Gbl77UiyoBxR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# eeg pre-processing\n",
        "def eeg_preprocessing(file, seizures, epoch_length = 10, step_size = 1, start_time = 0):\n",
        "    start = time.time()\n",
        "\n",
        "    # reading in data\n",
        "    raw = mne.io.read_raw_edf(file)\n",
        "\n",
        "    # apply filterbank\n",
        "    raw = raw.load_data().filter(l_freq=0.25, h_freq=25)\n",
        "    channels = raw.ch_names                                  # column names\n",
        "\n",
        "    # Divide into epochs\n",
        "    res = []\n",
        "    while start_time <= max(raw.times) + 0.01 - epoch_length:  # max(raw.times) = 3600\n",
        "#     while start_time <= 50 - epoch_length:  # max(raw.times) = 3600\n",
        "        features = []\n",
        "        start, stop = raw.time_as_index([start_time, start_time + epoch_length])\n",
        "        temp = raw[:, start:stop][0]\n",
        "\n",
        "        # start time as ID\n",
        "        features.append(start_time)\n",
        "\n",
        "        # features\n",
        "        for i in range(23):\n",
        "            features.extend(eeg_features(temp[i]).tolist())\n",
        "\n",
        "        # seizure flag for y\n",
        "        if file in seizures:  # if file has seizure\n",
        "            for seizure in seizures[file]:\n",
        "                if start_time > seizure[0] and start_time < seizure[1]:\n",
        "                    features.append(1)\n",
        "                elif start_time + epoch_length > seizure[0] and start_time + epoch_length < seizure[1]:\n",
        "                    features.append(1)\n",
        "                else:\n",
        "                    features.append(0)\n",
        "        else:\n",
        "            features.append(0)\n",
        "\n",
        "        res.append(features)\n",
        "        start_time += step_size\n",
        "        print(\"Section \", str(len(res)), \"; start: \", start, \" ; stop: \", stop)\n",
        "\n",
        "    # formatting\n",
        "    feature_names = [\"rms\", \"variance\", \"kurtosis\", \"skewness\", \"max_amp\", \"min_amp\", \"n_peaks\", \"n_crossings\",\n",
        "        \"hfd\", \"pfd\", \"hurst_exp\", \"spectral_entropy\", \"total_power\", \"median_freq\", \"peak_freq\",\n",
        "        \"hjorth_mobility\", \"hjorth_complexity\", \"power_1hz\", \"power_5hz\", \"power_10hz\", \"power_15hz\", \"power_20hz\"]\n",
        "\n",
        "    column_names = [\"start_time\"]\n",
        "    for channel in channels:\n",
        "        for name in feature_names:\n",
        "            column_names.append(channel + \"_\" + name)\n",
        "    column_names.append(\"seizure\")\n",
        "\n",
        "    res = pd.DataFrame(res, columns=column_names)\n",
        "\n",
        "    end = time.time()\n",
        "    print(\"Finished preprocessing \", file, f\" took {(end - start) / 60} minutes\")\n",
        "    return res"
      ],
      "metadata": {
        "id": "Lbv6mxUvoEXq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading and Preprocessing files"
      ],
      "metadata": {
        "id": "tuoZEHXfoQGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename to appropriate csv file\n",
        "data = pd.read_csv(f\"Patient_Files_Info 2.csv\", on_bad_lines='warn')\n",
        "data = data.reset_index()  # make sure indexes pair with number of rows\n",
        "seizures = {}\n",
        "files = {}\n",
        "\n",
        "for index, row in data.iterrows():\n",
        "  # Load in data fields for each file\n",
        "  patient_num = row[\"Patient\"]\n",
        "  file_name = row[\"File\"]\n",
        "  seizure_check = row[\"Seizure\"]\n",
        "  seizure_num = row[\"# of Seizures\"]\n",
        "\n",
        "  file_dir = f\"files/raw/patient{patient_num}/{file_name}\"\n",
        "\n",
        "  if patient_num not in files:\n",
        "    files[patient_num] = []\n",
        "\n",
        "  files[patient_num].append(file_dir)\n",
        "\n",
        "  # Check if file contains seizure\n",
        "  if seizure_check == \"Yes\":\n",
        "    seizures[file_dir] = []\n",
        "    seizure_count = 0\n",
        "\n",
        "    # Collect start-end pairings for all seizures within the file\n",
        "    for i in range(5, 5 + len(row[5:]), 2):\n",
        "      # Check that the pair is actually a seizure and not empty\n",
        "      if not np.isnan(row[i]):\n",
        "        seizure_count += 1\n",
        "        start = row[i]\n",
        "        end = row[i + 1]\n",
        "\n",
        "        # Check that the end of a seizure is after its start\n",
        "        if end > start:\n",
        "          seizures[file_dir].append([start, end])\n",
        "        else:\n",
        "          warnings.warn(f\"File {file_name}: End time ({end}) for seizure #{seizure_count} is earlier than start time ({start}).\")\n",
        "      else:\n",
        "        break\n",
        "\n",
        "    # Check that the number of seizures is equal to the number of start-end pairs\n",
        "    if len(seizures[file_dir]) != seizure_num:\n",
        "      warnings.warn(f\"File {file_name}: Number of start-end pairs ({len(seizures[file_dir])}) not equal to number of seizures ({seizure_num}).\")\n",
        "\n",
        "# Pre-process all files to create cumulative dataframe\n",
        "for patient in files:\n",
        "  patient_files = files[patient]\n",
        "\n",
        "  file1 = patient_files.pop(0)\n",
        "  res = eeg_preprocessing(file1, seizures)\n",
        "\n",
        "  for file in patient_files:\n",
        "    int_res = eeg_preprocessing(file, seizures)\n",
        "    res = pd.concat([res, int_res], ignore_index=True)\n",
        "\n",
        "  res.to_csv(f\"files/preprocessed/preprocessed_{patient_num}.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "JxmCzzjdoSoi",
        "outputId": "28b2ce44-4a0c-4e4f-862e-4029465713dc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting EDF parameters from /content/files/raw/patient1/chb01_01.edf...\n",
            "EDF file detected\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/files/raw/patient1/chb01_01.edf'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-691ba66f446e>\u001b[0m in \u001b[0;36m<cell line: 47>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0mfile1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatient_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m   \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meeg_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseizures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpatient_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-ce2f20a416bf>\u001b[0m in \u001b[0;36meeg_preprocessing\u001b[0;34m(file, seizures, epoch_length, step_size, start_time)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# reading in data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_raw_edf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# apply filterbank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mne/io/edf/edf.py\u001b[0m in \u001b[0;36mread_raw_edf\u001b[0;34m(input_fname, eog, misc, stim_channel, exclude, infer_types, include, preload, units, encoding, exclude_after_unique, verbose)\u001b[0m\n\u001b[1;32m   1698\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"edf\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Only EDF files are supported, got {ext}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1700\u001b[0;31m     return RawEDF(\n\u001b[0m\u001b[1;32m   1701\u001b[0m         \u001b[0minput_fname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m         \u001b[0meog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-321>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_fname, eog, misc, stim_channel, exclude, infer_types, preload, include, units, encoding, exclude_after_unique, verbose)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mne/io/edf/edf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_fname, eog, misc, stim_channel, exclude, infer_types, preload, include, units, encoding, exclude_after_unique, verbose)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Extracting EDF parameters from {input_fname}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0minput_fname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         info, edf_info, orig_units = _get_info(\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0minput_fname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mstim_channel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mne/io/edf/edf.py\u001b[0m in \u001b[0;36m_get_info\u001b[0;34m(fname, stim_channel, eog, misc, exclude, infer_types, preload, include, exclude_after_unique)\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[0mmisc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmisc\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmisc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m     edf_info, orig_units = _read_header(\n\u001b[0m\u001b[1;32m    545\u001b[0m         \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude_after_unique\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mne/io/edf/edf.py\u001b[0m in \u001b[0;36m_read_header\u001b[0;34m(fname, exclude, infer_types, include, exclude_after_unique)\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s file detected\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"bdf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"edf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         return _read_edf_header(\n\u001b[0m\u001b[1;32m    519\u001b[0m             \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude_after_unique\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mne/io/edf/edf.py\u001b[0m in \u001b[0;36m_read_edf_header\u001b[0;34m(fname, exclude, infer_types, include, exclude_after_unique)\u001b[0m\n\u001b[1;32m    807\u001b[0m     \u001b[0medf_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"events\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m         \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# version (unused here)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/files/raw/patient1/chb01_01.edf'"
          ]
        }
      ]
    }
  ]
}